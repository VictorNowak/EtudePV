{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb431851-ab8e-4d06-8e52-0aaa956af533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23ce17b-bcab-4a6f-b2b4-6016435f88f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D√©partements trait√©s:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ D√©partement 12 : 2 parcelles filtr√©es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D√©partements trait√©s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ 1248 parcelles non retrouv√©es export√©es dans 'parcelles_non_trouv√©es.xlsx'\n",
      "üìç Base de sites : 747\n",
      "Code site\n",
      "SITE_30524    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# üìÅ Dossier contenant les fichiers cadastraux convertis en .parquet\n",
    "data_dir = \"data_parquet\"\n",
    "excel_file = \"parcelle_keep.xlsx\"\n",
    "\n",
    "# üì• Charger la liste des parcelles √† conserver\n",
    "parcels_to_keep = pd.read_excel(excel_file, engine='openpyxl')\n",
    "parcels_to_keep = parcels_to_keep.dropna(subset=[\"commune\", \"section\", \"numero\"])\n",
    "parcels_to_keep = parcels_to_keep[parcels_to_keep['numero'] != 0]\n",
    "\n",
    "# Normalisation des champs\n",
    "parcels_to_keep['commune'] = parcels_to_keep['commune'].astype(str).str.strip()\n",
    "parcels_to_keep['section'] = parcels_to_keep['section'].astype(str).str.strip().str.upper()\n",
    "parcels_to_keep['numero'] = parcels_to_keep['numero'].astype(str).str.strip().str.zfill(4)\n",
    "parcels_to_keep['prefixe'] = parcels_to_keep['prefixe'].fillna(0).astype(float).astype(int).astype(str).str.zfill(3)\n",
    "\n",
    "# üì¶ Listes temporaires pour concat√©nation\n",
    "parcels_chunks = []\n",
    "buildings_chunks = []\n",
    "\n",
    "# üîÅ Parcourir les fichiers Parquet\n",
    "for filename in tqdm(os.listdir(data_dir), desc=\"D√©partements trait√©s\"):\n",
    "    if filename.endswith(\"-parcelles.parquet\"):\n",
    "        code_dept = filename.split(\"-\")[1].split(\".\")[0]\n",
    "        parcels_path = os.path.join(data_dir, f\"cadastre-{code_dept}-parcelles.parquet\")\n",
    "        buildings_path = os.path.join(data_dir, f\"cadastre-{code_dept}-batiments.parquet\")\n",
    "\n",
    "        parcels_gdf = gpd.read_parquet(parcels_path)\n",
    "        buildings_gdf = gpd.read_parquet(buildings_path)\n",
    "\n",
    "        # üßπ Nettoyage (Cadastre)\n",
    "        for col in ['commune', 'section', 'numero']:\n",
    "            parcels_gdf[col] = parcels_gdf[col].astype(str).str.strip()\n",
    "        parcels_gdf['section'] = parcels_gdf['section'].str.upper()\n",
    "        parcels_gdf['numero'] = parcels_gdf['numero'].astype(str).str.strip().str.zfill(4)\n",
    "        if 'prefixe' not in parcels_gdf.columns:\n",
    "            parcels_gdf['prefixe'] = \"000\"\n",
    "        else:\n",
    "            parcels_gdf['prefixe'] = parcels_gdf['prefixe'].fillna(\"000\").astype(str).str.strip().str.zfill(3)\n",
    "\n",
    "        # üéØ Filtrer uniquement les parcelles du d√©partement\n",
    "        communes_dept = parcels_gdf['commune'].unique()\n",
    "        subset_to_keep = parcels_to_keep[parcels_to_keep['commune'].isin(communes_dept)]\n",
    "\n",
    "        # üîç Filtrage exact\n",
    "        filtered_parcels = parcels_gdf.merge(\n",
    "            subset_to_keep,\n",
    "            on=['commune', 'section', 'numero', 'prefixe'],\n",
    "            how='inner'\n",
    "        )\n",
    "\n",
    "        print(f\"üìÇ D√©partement {code_dept} : {len(filtered_parcels)} parcelles filtr√©es\")\n",
    "\n",
    "        if filtered_parcels.empty:\n",
    "            continue\n",
    "\n",
    "        # üß≠ Intersection avec les b√¢timents\n",
    "        join_intersects = gpd.sjoin(\n",
    "            buildings_gdf,\n",
    "            filtered_parcels,\n",
    "            how='inner',\n",
    "            predicate='intersects'\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # Calcul du ratio de recouvrement\n",
    "        parcel_geometries = filtered_parcels.geometry.loc[join_intersects[\"index_right\"]].reset_index(drop=True)\n",
    "        join_intersects[\"intersection_area\"] = join_intersects.geometry.intersection(parcel_geometries).area\n",
    "        join_intersects[\"building_area\"] = join_intersects.geometry.area\n",
    "        join_intersects[\"coverage_ratio\"] = join_intersects[\"intersection_area\"] / join_intersects[\"building_area\"]\n",
    "        filtered_buildings = join_intersects[join_intersects[\"coverage_ratio\"] >= 0.5].copy()\n",
    "\n",
    "        # ‚ûï Ajouter aux listes\n",
    "        parcels_chunks.append(filtered_parcels)\n",
    "        buildings_chunks.append(filtered_buildings)\n",
    "\n",
    "# üß± Concat√©nation finale\n",
    "all_filtered_parcels = pd.concat(parcels_chunks, ignore_index=True)\n",
    "all_filtered_buildings = pd.concat(buildings_chunks, ignore_index=True)\n",
    "\n",
    "all_filtered_parcels.set_crs(\"EPSG:4326\", inplace=True)\n",
    "all_filtered_buildings.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# üíæ Export\n",
    "all_filtered_parcels.to_file(\"parcelles_filtr√©es.geojson\", driver=\"GeoJSON\")\n",
    "all_filtered_buildings.to_file(\"parcelles_filtr√©es.geojson\", driver=\"GeoJSON\")\n",
    "all_filtered_parcels[['commune', 'section', 'numero', 'prefixe']].to_excel(\"parcelles_trouv√©es.xlsx\", index=False)\n",
    "\n",
    "# Apr√®s concat√©nation finale\n",
    "merged_all = parcels_to_keep.merge(\n",
    "    all_filtered_parcels,\n",
    "    on=['commune', 'section', 'numero', 'prefixe'],\n",
    "    how='left',\n",
    "    indicator=True,\n",
    "    suffixes=('','_right')\n",
    ")\n",
    "\n",
    "# Parcelles absentes dans les r√©sultats\n",
    "cols_to_export = ['Code site', 'commune', 'section', 'numero', 'prefixe']\n",
    "missing = merged_all[merged_all['_merge'] == 'left_only'][cols_to_export]\n",
    "missing.to_excel(\"parcelles_non_trouv√©es.xlsx\", index=False)\n",
    "\n",
    "print(f\"üì§ {len(missing)} parcelles non retrouv√©es export√©es dans 'parcelles_non_trouv√©es.xlsx'\")\n",
    "\n",
    "# üìä Statistiques\n",
    "print(f\"üìç Base de sites : {len(parcels_to_keep['Code site'].unique())}\")\n",
    "trouvees_par_code_site = merged_all[merged_all['_merge'] == 'both']['Code site'].value_counts()\n",
    "print(trouvees_par_code_site.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53652f68-9327-4645-b127-5d5020289fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
